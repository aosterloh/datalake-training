{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3TwAK_8Wll0"
   },
   "source": [
    "## 3. Data Scientist - Create ML models with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rwCbd6SqWll0"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g7hujos_zCwi"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".appName('Spark - Data Scientist Demo') \\\n",
    ".config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest.jar') \\\n",
    ".config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.18.0\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mZAK-gbxzCwj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'version 2.12.10'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.app.id\")\n",
    "spark.sparkContext._jvm.scala.util.Properties.versionString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ylnHDJ13zCwj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thetraining-project:thetraining_project_raw.transaction_data_train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_id = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "bq_raw_dataset_name = project_id[0] + '-raw'\n",
    "bq_raw_dataset_name = bq_raw_dataset_name.replace('-', '_')\n",
    "bq_raw_table_path = project_id[0] + ':' + bq_raw_dataset_name + '.transaction_data_train' \n",
    "bq_raw_table_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asGBbiH5zCwk"
   },
   "source": [
    "#### Load Training Data using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p20yxBKHzCwl"
   },
   "outputs": [],
   "source": [
    "data = spark.read \\\n",
    ".format(\"bigquery\") \\\n",
    ".option(\"table\", bq_raw_table_path) \\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_y4K036kzCwn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[step: bigint, type: string, amount: double, oldbalanceOrg: double, newbalanceOrig: double, oldbalanceDest: double, newbalanceDest: double, isFraud: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('transactionID')\n",
    "data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling the minority label (isFraud=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 780\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "\n",
    "major_df = data.filter(col(\"isFraud\") == 0)\n",
    "minor_df = data.filter(col(\"isFraud\") == 1)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----------+-------------+--------------+--------------+--------------+-------+\n",
      "|step|    type|    amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|\n",
      "+----+--------+----------+-------------+--------------+--------------+--------------+-------+\n",
      "| 302|TRANSFER| 419955.64|      20978.0|           0.0|       30562.0|     751695.31|      0|\n",
      "| 322|TRANSFER| 169566.23|       3832.0|           0.0|    2717714.64|    2887280.87|      0|\n",
      "| 540|TRANSFER|1348788.69|        675.0|           0.0|     171461.44|    1520250.13|      0|\n",
      "| 349|TRANSFER| 790428.92|         66.0|           0.0|     305371.89|    1095800.81|      0|\n",
      "|   8|TRANSFER|1746499.66|        209.0|           0.0|       75521.0|     2180688.8|      0|\n",
      "| 156|TRANSFER|1350240.79|     112105.0|           0.0|    1972716.25|    3322957.04|      0|\n",
      "| 254|TRANSFER| 166272.49|      51930.0|           0.0|    7321489.31|     7487761.8|      0|\n",
      "| 476|TRANSFER| 223746.33|     160672.0|           0.0|     527244.84|     750991.17|      0|\n",
      "| 255|TRANSFER|  15313.91|      11121.0|           0.0|     398058.23|     413372.14|      0|\n",
      "| 322|TRANSFER|2716031.13|      20733.0|           0.0|      20897.17|    2736928.31|      0|\n",
      "|  34|TRANSFER|1189366.26|        709.0|           0.0|    1796142.72|    2985508.98|      0|\n",
      "| 249|TRANSFER|  57120.96|      33146.0|           0.0|    1924735.09|    1981856.05|      0|\n",
      "| 301|TRANSFER|1828796.61|       1525.0|           0.0|    5976787.56|    7805584.17|      0|\n",
      "| 566|TRANSFER|1501845.51|      25414.0|           0.0|    2833330.71|    4335176.22|      0|\n",
      "| 229|TRANSFER|  45463.75|      25932.0|           0.0|     432846.94|     478310.68|      0|\n",
      "| 179|TRANSFER| 556575.78|      57317.0|           0.0|     659806.45|    1216382.24|      0|\n",
      "| 448|TRANSFER| 298326.77|      49806.0|           0.0|      378650.9|     676977.67|      0|\n",
      "| 153|TRANSFER|1145194.97|     144541.0|           0.0|      22857.27|    1288138.93|      0|\n",
      "| 282|TRANSFER| 187202.35|    233548.16|      46345.82|     211665.78|     398868.12|      0|\n",
      "| 369|TRANSFER| 877676.02|     59827.53|           0.0|    1838777.08|     2716453.1|      0|\n",
      "+----+--------+----------+-------------+--------------+--------------+--------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# duplicate the minority rows\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in range(ratio)]))).drop('dummy')\n",
    "# combine both oversampled minority rows and previous majority rows\n",
    "data = major_df.unionAll(oversampled_df)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGTkXZhtzCwn"
   },
   "source": [
    "#### Create a pyspark ML pipeline \n",
    "\n",
    "The pipeline will transform the features and train a Decision Tree classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2kg4ewsvzCwo"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier\n",
    "\n",
    "\n",
    "categorical_cols = [field for (field, data_type) in data.dtypes \n",
    "                    if ((data_type == \"string\") & (field != 'isFraud'))]\n",
    "\n",
    "ohe_output_cols = [x + \"_OHE\" for x in categorical_cols]\n",
    "\n",
    "string_indexers = StringIndexer(inputCol='type', outputCol='type' +\"_Index\").fit(data) \n",
    "\n",
    "one_hot_indexer = OneHotEncoder(inputCol='type_Index', outputCol='type' +\"_OHE\")\n",
    "\n",
    "numeric_cols = [field for (field, data_type) in data.dtypes \n",
    "                if (((data_type == \"double\") | (data_type == \"int\") | (data_type == \"bigint\"))\n",
    "                  & (field != 'isFraud'))]\n",
    "\n",
    "assembler_inputs = ohe_output_cols + numeric_cols\n",
    "\n",
    "vec_assembler = VectorAssembler(\n",
    "    inputCols=assembler_inputs,\n",
    "    outputCol=\"features\")\n",
    "\n",
    "#DecisionTree\n",
    "dtc = DecisionTreeClassifier(labelCol=\"isFraud\", featuresCol=\"features\", maxDepth=3, maxBins=12)\n",
    "# #Linear Regression\n",
    "# dtc = LogisticRegression(labelCol=\"isFraud\", featuresCol=\"features\", maxIter=10, )\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    string_indexers,\n",
    "    one_hot_indexer,\n",
    "    vec_assembler,\n",
    "    dtc \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(dtc.maxDepth, [3, 6, 10, 11 ]) \\\n",
    "    .addGrid(dtc.maxBins, [12, 24, 200]) \\\n",
    "    .build()\n",
    "# #Linear Regression\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "#     .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol=\"isFraud\"),\n",
    "                          numFolds=2)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "model = crossval.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--lPFc7mzCwp"
   },
   "source": [
    "#### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kGU9h1-rzCwq"
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqH9COddzCwq"
   },
   "source": [
    "#### Persist the model to GCS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cnoutgo2zCwq"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "gcs_bucket = project_id[0] + '-data'\n",
    "model_path = f'gs://{gcs_bucket}/model/'\n",
    "# model = model.bestModel\n",
    "model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on test data\n",
    "**TODO** \n",
    "\n",
    "* Provide path_to_predict_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DdasXGm7zCws"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- transactionID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_predict_csv = \"gs://thetraining-project-data/transaction_data_test.csv\"\n",
    "df_transaction_data_predict_from_csv = spark \\\n",
    ".read \\\n",
    ".option(\"inferSchema\" , \"true\") \\\n",
    ".option(\"header\" , \"true\") \\\n",
    ".csv(path_to_predict_csv)\n",
    "df_transaction_data_predict_from_csv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRp9QM2jzCws"
   },
   "source": [
    "Load the saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YFjQsf5pzCws"
   },
   "outputs": [],
   "source": [
    "loaded_pipeline_model = PipelineModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Wd2X6ZbBzCwt"
   },
   "outputs": [],
   "source": [
    "predictions = loaded_pipeline_model.transform(df_transaction_data_predict_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BaR6_kfazCwt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+-------------+--------------+--------------+--------------+-------+--------------------+----------+---------+--------------------+--------------------+--------------------+----------+\n",
      "|step| type| amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|       transactionID|type_Index| type_OHE|            features|       rawPrediction|         probability|prediction|\n",
      "+----+-----+-------+-------------+--------------+--------------+--------------+-------+--------------------+----------+---------+--------------------+--------------------+--------------------+----------+\n",
      "| 310|DEBIT|3334.31|     102439.0|      99104.69|     962290.61|     965624.92|      0|818ca43a-9ac9-484...|       4.0|(4,[],[])|[0.0,0.0,0.0,0.0,...|  [1420940.0,2340.0]|[0.99835591029172...|       0.0|\n",
      "| 351|DEBIT|5268.56|        468.0|           0.0|    1672373.71|    1677642.27|      0|70948920-5fa6-401...|       4.0|(4,[],[])|(10,[4,5,6,8,9],[...|[3265139.0,408720.0]|[0.88874913272392...|       0.0|\n",
      "| 592|DEBIT| 3016.8|      62038.0|       59021.2|    9669792.89|    9672809.69|      0|c6bbbaf0-55bb-4e9...|       4.0|(4,[],[])|[0.0,0.0,0.0,0.0,...|  [1420940.0,2340.0]|[0.99835591029172...|       0.0|\n",
      "| 286|DEBIT|2005.45|     462875.0|     460869.55|     757666.15|      759671.6|      0|a8b178e2-6e70-42f...|       4.0|(4,[],[])|[0.0,0.0,0.0,0.0,...|  [1420940.0,2340.0]|[0.99835591029172...|       0.0|\n",
      "| 157|DEBIT|7422.22|      20639.0|      13216.78|    3957547.41|    3964969.63|      0|9931bfd1-0b59-4d3...|       4.0|(4,[],[])|[0.0,0.0,0.0,0.0,...|[3265139.0,408720.0]|[0.88874913272392...|       0.0|\n",
      "+----+-----+-------+-------------+--------------+--------------+--------------+-------+--------------------+----------+---------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2FFk6q7fzCwt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|prediction|isFraud|\n",
      "+----------+-------+\n",
      "|       0.0|      0|\n",
      "|       0.0|      0|\n",
      "|       0.0|      0|\n",
      "|       0.0|      0|\n",
      "|       0.0|      0|\n",
      "+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"isFraud\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBMiTQJqzCwu"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_KYod7wWzCwu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8908125351606421\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "binaryEvaluator = BinaryClassificationEvaluator(labelCol=\"isFraud\")\n",
    "\n",
    "auc = binaryEvaluator.evaluate(predictions, {binaryEvaluator.metricName: \"areaUnderROC\"})\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FXJV0AQgzCwu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_np = np.array((predictions.select(\"isFraud\",\"prediction\").collect()))\n",
    "tests_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SCbijvh6zCwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.03849006322828806\n",
      "precision: 0.0196647614154518\n",
      "recall: 0.9016489988221437\n"
     ]
    }
   ],
   "source": [
    "tests_np = np.array((predictions.select(\"isFraud\",\"prediction\").collect()))\n",
    "\n",
    "np_acc = accuracy_score(tests_np[:,0], tests_np[:,1])\n",
    "np_f1 = f1_score(tests_np[:,0], tests_np[:,1])\n",
    "np_precision = precision_score(tests_np[:,0], tests_np[:,1])\n",
    "np_recall = recall_score(tests_np[:,0], tests_np[:,1])\n",
    "np_auc = roc_auc_score(tests_np[:,0], tests_np[:,1])\n",
    "\n",
    "print(\"f1:\", np_f1)\n",
    "print(\"precision:\", np_precision)\n",
    "print(\"recall:\", np_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlDr0C5DzCwv"
   },
   "source": [
    "#### Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "D0-_eqAszCwv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Positive(1)</th>\n",
       "      <th>Predicted Negative(0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Positive(1)</th>\n",
       "      <td>1531</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Negative(0)</th>\n",
       "      <td>76324</td>\n",
       "      <td>1193906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Positive(1)  Predicted Negative(0)\n",
       "Actual Positive(1)                   1531                    167\n",
       "Actual Negative(0)                  76324                1193906"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import package that will generate the confusion matrix scores\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import packages that will help display the scores\n",
    "import pandas as pd\n",
    "\n",
    "confusion_matrix_scores = confusion_matrix(tests_np[:,0], \n",
    "                                           tests_np[:,1], \n",
    "                                           labels=[1, 0])\n",
    "\n",
    "# display scores as a heatmap\n",
    "df = pd.DataFrame(confusion_matrix_scores, \n",
    "                  columns = [\"Predicted Positive(1)\", \"Predicted Negative(0)\"],\n",
    "                  index = [\"Actual Positive(1)\", \"Actual Negative(0)\"])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8Q3YHVvezCww"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thetraining_project_annotated.transaction_data_predictions'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_annotated_table_name = 'transaction_data_predictions'\n",
    "bq_annotated_table_path=  project_id[0] +  '_annotated.' + bq_annotated_table_name\n",
    "bq_annotated_table_path = bq_annotated_table_path.replace('-', '_')\n",
    "bq_annotated_table_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDn4bdq1zCww"
   },
   "source": [
    "#### Persist predictions as an annotated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "vwfUAozUzCwx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Table 'thetraining-\n",
      "project:thetraining_project_annotated.transaction_data_predictions' could not be\n",
      "created; a table with this name already exists.\n"
     ]
    }
   ],
   "source": [
    "schema_inline = predictions.schema.simpleString().replace('struct<', '').replace('>', '').replace('int', 'int64').replace('double', 'float64').replace('bigint64', 'int64').replace('vector', 'STRING')\n",
    "\n",
    "!bq mk --table \\\n",
    "{bq_annotated_table_path} \\\n",
    "{schema_inline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'step:int64,type:string,amount:float64,oldbalanceOrg:float64,newbalanceOrig:float64,oldbalanceDest:float64,newbalanceDest:float64,isFraud:int64,transactionID:string,type_Index:float64,type_OHE:STRING,features:STRING,rawPrediction:STRING,probability:STRING,prediction:float64'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mKDzZWhTzCwx"
   },
   "outputs": [],
   "source": [
    "predictions.write \\\n",
    ".format(\"bigquery\") \\\n",
    ".option(\"table\", project_id[0]  + ':' + bq_annotated_table_path) \\\n",
    ".option(\"temporaryGcsBucket\", project_id[0]  + '-data') \\\n",
    ".mode('overwrite') \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "B6EreECmzCwy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thetraining_project_annotated'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_dataset_name =  project_id[0] +  '_annotated'\n",
    "annotated_dataset_name = annotated_dataset_name.replace('-', '_')\n",
    "annotated_dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGwxhnHGzCwy"
   },
   "source": [
    "**TODO** \n",
    "* Add annotated_dataset_name in the FROM clause below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2-gJPCtxzCwz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "      <th>is_insertable_into</th>\n",
       "      <th>is_typed</th>\n",
       "      <th>creation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thetraining-project</td>\n",
       "      <td>thetraining_project_annotated</td>\n",
       "      <td>transaction_data_workflow</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2021-03-15 11:41:26.369000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thetraining-project</td>\n",
       "      <td>thetraining_project_annotated</td>\n",
       "      <td>transaction_data_predictions</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2021-03-03 09:56:08.781000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         table_catalog                   table_schema  \\\n",
       "0  thetraining-project  thetraining_project_annotated   \n",
       "1  thetraining-project  thetraining_project_annotated   \n",
       "\n",
       "                     table_name  table_type is_insertable_into is_typed  \\\n",
       "0     transaction_data_workflow  BASE TABLE                YES       NO   \n",
       "1  transaction_data_predictions  BASE TABLE                YES       NO   \n",
       "\n",
       "                     creation_time  \n",
       "0 2021-03-15 11:41:26.369000+00:00  \n",
       "1 2021-03-03 09:56:08.781000+00:00  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT * FROM thetraining_project_annotated.INFORMATION_SCHEMA.TABLES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbZpvQ9nzCwz"
   },
   "source": [
    "#### Join buisness data to enrich the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k00qmMINzCwz"
   },
   "source": [
    "**TODO** \n",
    "* Provide the path to the join csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zf_shWXdzCw0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- transactionID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_join_csv = \"gs://thetraining-project-data/transaction_data_join.csv\"\n",
    "df_transaction_data_join_from_csv = spark \\\n",
    ".read \\\n",
    ".option(\"inferSchema\" , \"true\") \\\n",
    ".option(\"header\" , \"true\") \\\n",
    ".csv(path_to_join_csv)\n",
    "df_transaction_data_join_from_csv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjGflyBOzCw0"
   },
   "source": [
    "**TODO** (Challenge 2)\n",
    "* Join the 2 spark dataframes (predictions & df_transaction_data_join_from_csv) on transactionID field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "pm-AH24IzCw1"
   },
   "outputs": [],
   "source": [
    "joined_result = predictions.join(df_transaction_data_join_from_csv, \"transactionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vFE7tsZczCw1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------+---------+-------------+--------------+--------------+--------------+-------+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-----------+\n",
      "|       transactionID|step|    type|   amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|type_Index|     type_OHE|            features|       rawPrediction|         probability|prediction|   nameOrig|   nameDest|\n",
      "+--------------------+----+--------+---------+-------------+--------------+--------------+--------------+-------+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-----------+\n",
      "|0013918d-0cdc-4e2...| 306|   DEBIT|  1244.34|      30927.0|      29682.66|    3248801.84|    3250046.18|      0|       4.0|    (4,[],[])|[0.0,0.0,0.0,0.0,...|[3265139.0,408720.0]|[0.88874913272392...|       0.0| C831886474|C1847064333|\n",
      "|00162366-932d-4fc...| 204|CASH_OUT|203860.23|          0.0|           0.0|     336504.92|     540365.16|      0|       0.0|(4,[0],[1.0])|(10,[0,4,5,8,9],[...|[3265139.0,408720.0]|[0.88874913272392...|       0.0| C896728022| C331131087|\n",
      "|0022ef6a-0ee3-4e8...|  13|CASH_OUT| 382105.5|          0.0|           0.0|    2750925.15|    3133030.66|      0|       0.0|(4,[0],[1.0])|(10,[0,4,5,8,9],[...|[3265139.0,408720.0]|[0.88874913272392...|       0.0|C1150532907|C1660526430|\n",
      "|003402a4-bc23-4f2...| 178| PAYMENT| 27994.13|      69545.0|      41550.87|           0.0|           0.0|      0|       2.0|(4,[2],[1.0])|(10,[2,4,5,6,7],[...|  [1420940.0,2340.0]|[0.99835591029172...|       0.0|C1260774996| M740485457|\n",
      "|0036a79e-5f07-4ec...| 209|CASH_OUT|329965.55|        456.0|           0.0|           0.0|     329965.55|      0|       0.0|(4,[0],[1.0])|(10,[0,4,5,6,9],[...|[3265139.0,408720.0]|[0.88874913272392...|       0.0|C1471278494| C408482446|\n",
      "+--------------------+----+--------+---------+-------------+--------------+--------------+--------------+-------+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "a2uQsRCbzCw2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1271928"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_result.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9K33zizTzCw2"
   },
   "source": [
    "#### Persist result as an enriched dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "QsiOiwSOzCw2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thetraining-project:thetraining_project_enriched.transaction_analysis_enriched'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_enriched_table_name = 'transaction_analysis_enriched'\n",
    "bq_enriched_table_path = project_id[0] +  '_enriched.' + bq_enriched_table_name\n",
    "bq_enriched_table_path = bq_enriched_table_path.replace('-', '_')\n",
    "bq_enriched_table_path = project_id[0] + ':' + bq_enriched_table_path\n",
    "bq_enriched_table_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "6zl_7sFOzCw2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Table 'thetraining-\n",
      "project:thetraining_project_enriched.transaction_analysis_enriched' could not be\n",
      "created; a table with this name already exists.\n"
     ]
    }
   ],
   "source": [
    "schema_inline = joined_result.schema.simpleString().replace('struct<', '').replace('>', '').replace('int', 'int64').replace('bigint64', 'int64').replace('double', 'float64').replace('vector', 'STRING')\n",
    "\n",
    "!bq mk --table \\\n",
    "{bq_enriched_table_path} \\\n",
    "{schema_inline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transactionID:string,step:int64,type:string,amount:float64,oldbalanceOrg:float64,newbalanceOrig:float64,oldbalanceDest:float64,newbalanceDest:float64,isFraud:int64,type_Index:float64,type_OHE:STRING,features:STRING,rawPrediction:STRING,probability:STRING,prediction:float64,nameOrig:string,nameDest:string'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "xG1fvtj6zCw3"
   },
   "outputs": [],
   "source": [
    "joined_result.write \\\n",
    ".format(\"bigquery\") \\\n",
    ".option(\"table\", bq_enriched_table_path) \\\n",
    ".option(\"temporaryGcsBucket\", project_id[0]  + '-data') \\\n",
    ".mode('overwrite') \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "dN-MyDCszCw3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thetraining_project_enriched'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_dataset_name = project_id[0] +  '_enriched'\n",
    "enriched_dataset_name = enriched_dataset_name.replace('-', '_')\n",
    "enriched_dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtXtLcrXzCw3"
   },
   "source": [
    "**TODO**\n",
    "* Provide the enriched_dataset_name in the FROM clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "nbiRVokHzCw4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "      <th>is_insertable_into</th>\n",
       "      <th>is_typed</th>\n",
       "      <th>creation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thetraining-project</td>\n",
       "      <td>thetraining_project_enriched</td>\n",
       "      <td>transaction_analysis_enriched</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2021-03-03 12:09:03.854000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         table_catalog                  table_schema  \\\n",
       "0  thetraining-project  thetraining_project_enriched   \n",
       "\n",
       "                      table_name  table_type is_insertable_into is_typed  \\\n",
       "0  transaction_analysis_enriched  BASE TABLE                YES       NO   \n",
       "\n",
       "                     creation_time  \n",
       "0 2021-03-03 12:09:03.854000+00:00  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT * FROM thetraining_project_enriched.INFORMATION_SCHEMA.TABLES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* Query the enriched table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY96LzmUzCw4"
   },
   "source": [
    "**TODO** (Optional: Challenge 3)\n",
    "* Improve the ML pipeline\n",
    "    * Try out different ML models [[doc]](https://spark.apache.org/docs/latest/ml-pipeline.html)\n",
    "    * Explore hyperparameter tuning \n",
    "    * How would you split the data when there is class imbalance? "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "3_Data_Scientist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
